Warning: 3 rows excluded due to sparse bins.
Train Language(s): ['en', 'hu']
Train Set: ('Len: 31997', 'Tokens: 272061', 'Unique: 59016', "Entities: {'O': 164316, 'I-ORG': 27929, 'I-PER': 20485, 'B-LOC': 16622, 'I-LOC': 14402, 'B-PER': 14299, 'B-ORG': 14008}")
Val Set: ('Len: 8000', 'Tokens: 68042', 'Unique: 21611', "Entities: {'O': 41584, 'I-ORG': 6775, 'I-PER': 5191, 'B-LOC': 3951, 'B-PER': 3736, 'B-ORG': 3484, 'I-LOC': 3321}")
Test Set(en): ('Len: 10001', 'Tokens: 80535', 'Unique: 20221', "Entities: {'O': 40875, 'I-ORG': 11638, 'I-PER': 7520, 'I-LOC': 6357, 'B-LOC': 4834, 'B-ORG': 4676, 'B-PER': 4635}")
Test Set(it): ('Len: 10000', 'Tokens: 80005', 'Unique: 18461', "Entities: {'O': 47357, 'I-ORG': 8992, 'I-PER': 5863, 'B-PER': 4911, 'B-LOC': 4600, 'I-LOC': 4166, 'B-ORG': 4116}")
Test Set(af): ('Len: 1000', 'Tokens: 10894', 'Unique: 3404', "Entities: {'O': 7764, 'I-ORG': 911, 'B-ORG': 583, 'I-PER': 548, 'B-LOC': 529, 'B-PER': 370, 'I-LOC': 189}")
Test Set(sw): ('Len: 1000', 'Tokens: 5609', 'Unique: 1830', "Entities: {'O': 2412, 'I-ORG': 696, 'I-PER': 674, 'I-LOC': 618, 'B-LOC': 452, 'B-PER': 403, 'B-ORG': 354}")
Test Set(de): ('Len: 10000', 'Tokens: 97805', 'Unique: 23570', "Entities: {'O': 69057, 'I-PER': 6539, 'I-ORG': 6107, 'B-LOC': 4968, 'B-PER': 4569, 'B-ORG': 4281, 'I-LOC': 2284}")
Trainable parameters:  278,224,135
[[0.20043183574080467], [0.3144856548537842], [0.25417461615210524], [0.2049305336549878], [0.8678700365126133], [0.23303102832823136]]
0.20043183574080467
Epoch 1/20, train_loss: 0.2330, avg_val_loss: 0.2004
[[0.20043183574080467, 0.17715961693227292], [0.3144856548537842, 0.2821718047911557], [0.25417461615210524, 0.23519180167597323], [0.2049305336549878, 0.21030603256076574], [0.8678700365126133, 0.9398530181497335], [0.23303102832823136, 0.22187156538470104]]
0.17715961693227292
Epoch 2/20, train_loss: 0.2669, avg_val_loss: 0.1772
[[0.20043183574080467, 0.17715961693227292, 0.1674958397746086], [0.3144856548537842, 0.2821718047911557, 0.26886681599405626], [0.25417461615210524, 0.23519180167597323, 0.24397060220329145], [0.2049305336549878, 0.21030603256076574, 0.19766823342069983], [0.8678700365126133, 0.9398530181497335, 0.9478856045752764], [0.23303102832823136, 0.22187156538470104, 0.22185891523909645]]
0.1674958397746086
Epoch 3/20, train_loss: 0.0565, avg_val_loss: 0.1675
[[0.20043183574080467, 0.17715961693227292, 0.1674958397746086, 0.1681407618522644], [0.3144856548537842, 0.2821718047911557, 0.26886681599405626, 0.2618253459802832], [0.25417461615210524, 0.23519180167597323, 0.24397060220329145, 0.2511432130758564], [0.2049305336549878, 0.21030603256076574, 0.19766823342069983, 0.21350301196798682], [0.8678700365126133, 0.9398530181497335, 0.9478856045752764, 0.9525349326431751], [0.23303102832823136, 0.22187156538470104, 0.22185891523909645, 0.2238539330328044]]
0.1681407618522644
Epoch 4/20, train_loss: 0.2452, avg_val_loss: 0.1681
[[0.20043183574080467, 0.17715961693227292, 0.1674958397746086, 0.1681407618522644, 0.1723739097714424], [0.3144856548537842, 0.2821718047911557, 0.26886681599405626, 0.2618253459802832, 0.2695718676375505], [0.25417461615210524, 0.23519180167597323, 0.24397060220329145, 0.2511432130758564, 0.2742919858556967], [0.2049305336549878, 0.21030603256076574, 0.19766823342069983, 0.21350301196798682, 0.24452525191009045], [0.8678700365126133, 0.9398530181497335, 0.9478856045752764, 0.9525349326431751, 1.0506539214402437], [0.23303102832823136, 0.22187156538470104, 0.22185891523909645, 0.2238539330328044, 0.23662744842160244]]
0.1723739097714424
Epoch 5/20, train_loss: 0.2274, avg_val_loss: 0.1724
[[0.20043183574080467, 0.17715961693227292, 0.1674958397746086, 0.1681407618522644, 0.1723739097714424, 0.17460055315494538], [0.3144856548537842, 0.2821718047911557, 0.26886681599405626, 0.2618253459802832, 0.2695718676375505, 0.27329732478855134], [0.25417461615210524, 0.23519180167597323, 0.24397060220329145, 0.2511432130758564, 0.2742919858556967, 0.28154486934312234], [0.2049305336549878, 0.21030603256076574, 0.19766823342069983, 0.21350301196798682, 0.24452525191009045, 0.24372521182522178], [0.8678700365126133, 0.9398530181497335, 0.9478856045752764, 0.9525349326431751, 1.0506539214402437, 1.0632889959961176], [0.23303102832823136, 0.22187156538470104, 0.22185891523909645, 0.2238539330328044, 0.23662744842160244, 0.24409354153199317]]
0.17460055315494538
Epoch 6/20, train_loss: 0.0207, avg_val_loss: 0.1746
Early stopping at epoch 6 as avg validation loss has not decreased for 3 epochs since epoch-2.
Test Set(en): ('Len: 10001', 'Tokens: 80535', 'Unique: 20221', "Entities: {'O': 40875, 'I-ORG': 11638, 'I-PER': 7520, 'I-LOC': 6357, 'B-LOC': 4834, 'B-ORG': 4676, 'B-PER': 4635}")
Test Set(it): ('Len: 10000', 'Tokens: 80005', 'Unique: 18461', "Entities: {'O': 47357, 'I-ORG': 8992, 'I-PER': 5863, 'B-PER': 4911, 'B-LOC': 4600, 'I-LOC': 4166, 'B-ORG': 4116}")
Test Set(af): ('Len: 1000', 'Tokens: 10894', 'Unique: 3404', "Entities: {'O': 7764, 'I-ORG': 911, 'B-ORG': 583, 'I-PER': 548, 'B-LOC': 529, 'B-PER': 370, 'I-LOC': 189}")
Test Set(sw): ('Len: 1000', 'Tokens: 5609', 'Unique: 1830', "Entities: {'O': 2412, 'I-ORG': 696, 'I-PER': 674, 'I-LOC': 618, 'B-LOC': 452, 'B-PER': 403, 'B-ORG': 354}")
Test Set(de): ('Len: 10000', 'Tokens: 97805', 'Unique: 23570', "Entities: {'O': 69057, 'I-PER': 6539, 'I-ORG': 6107, 'B-LOC': 4968, 'B-PER': 4569, 'B-ORG': 4281, 'I-LOC': 2284}")
LANG [en]: F1-score (Token-level) : 0.835
Test Loss: 0.27329732478855134 
 Test Evaluation (strict IOB2):
              precision    recall  f1-score   support

         LOC      0.872     0.859     0.865      9463
         ORG      0.762     0.765     0.763      7848
         PER      0.891     0.914     0.902      7491

   micro avg      0.843     0.846     0.844     24802
   macro avg      0.841     0.846     0.844     24802
weighted avg      0.843     0.846     0.844     24802

LANG [it]: F1-score (Token-level) : 0.842
Test Loss: 0.28154486934312234 
 Test Evaluation (strict IOB2):
              precision    recall  f1-score   support

         LOC      0.843     0.776     0.808      9427
         ORG      0.753     0.826     0.788      7224
         PER      0.939     0.949     0.944      8423

   micro avg      0.847     0.849     0.848     25074
   macro avg      0.845     0.850     0.847     25074
weighted avg      0.849     0.849     0.848     25074

LANG [af]: F1-score (Token-level) : 0.835
Test Loss: 0.24372521182522178 
 Test Evaluation (strict IOB2):
              precision    recall  f1-score   support

         LOC      0.800     0.874     0.836      1296
         ORG      0.775     0.846     0.809      1304
         PER      0.869     0.953     0.909       666

   micro avg      0.804     0.879     0.840      3266
   macro avg      0.814     0.891     0.851      3266
weighted avg      0.804     0.879     0.840      3266

LANG [sw]: F1-score (Token-level) : 0.663
Test Loss: 1.0632889959961176 
 Test Evaluation (strict IOB2):
              precision    recall  f1-score   support

         LOC      0.625     0.725     0.671       908
         ORG      0.531     0.442     0.482       701
         PER      0.857     0.846     0.852       617

   micro avg      0.664     0.669     0.667      2226
   macro avg      0.671     0.671     0.668      2226
weighted avg      0.660     0.669     0.662      2226

LANG [de]: F1-score (Token-level) : 0.806
Test Loss: 0.24409354153199317 
 Test Evaluation (strict IOB2):
              precision    recall  f1-score   support

         LOC      0.814     0.840     0.827     11290
         ORG      0.690     0.771     0.728      9151
         PER      0.921     0.859     0.889      7933

   micro avg      0.798     0.823     0.810     28374
   macro avg      0.809     0.823     0.815     28374
weighted avg      0.804     0.823     0.812     28374

Time Elapsed:  4018.4110548496246
