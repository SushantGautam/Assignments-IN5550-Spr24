Warning: 3 rows excluded due to sparse bins.
Train Language(s): ['en', 'hu', 'af', 'it', 'de']
Train Set: ('Len: 67998', 'Tokens: 602876', 'Unique: 110309', "Entities: {'O': 383812, 'I-ORG': 55407, 'I-PER': 42888, 'B-LOC': 34343, 'B-PER': 31273, 'B-ORG': 29612, 'I-LOC': 25541}")
Val Set: ('Len: 17000', 'Tokens: 150662', 'Unique: 41511', "Entities: {'O': 96172, 'I-ORG': 13574, 'I-PER': 10628, 'B-LOC': 8579, 'B-PER': 7688, 'B-ORG': 7466, 'I-LOC': 6555}")
Test Set(en): ('Len: 10001', 'Tokens: 80535', 'Unique: 20221', "Entities: {'O': 40875, 'I-ORG': 11638, 'I-PER': 7520, 'I-LOC': 6357, 'B-LOC': 4834, 'B-ORG': 4676, 'B-PER': 4635}")
Test Set(it): ('Len: 10000', 'Tokens: 80005', 'Unique: 18461', "Entities: {'O': 47357, 'I-ORG': 8992, 'I-PER': 5863, 'B-PER': 4911, 'B-LOC': 4600, 'I-LOC': 4166, 'B-ORG': 4116}")
Test Set(af): ('Len: 1000', 'Tokens: 10894', 'Unique: 3404', "Entities: {'O': 7764, 'I-ORG': 911, 'B-ORG': 583, 'I-PER': 548, 'B-LOC': 529, 'B-PER': 370, 'I-LOC': 189}")
Test Set(sw): ('Len: 1000', 'Tokens: 5609', 'Unique: 1830', "Entities: {'O': 2412, 'I-ORG': 696, 'I-PER': 674, 'I-LOC': 618, 'B-LOC': 452, 'B-PER': 403, 'B-ORG': 354}")
Test Set(de): ('Len: 10000', 'Tokens: 97805', 'Unique: 23570', "Entities: {'O': 69057, 'I-PER': 6539, 'I-ORG': 6107, 'B-LOC': 4968, 'B-PER': 4569, 'B-ORG': 4281, 'I-LOC': 2284}")
Trainable parameters:  278,224,135
[[0.17237977705601798], [0.28971270478952427], [0.15825580240200504], [0.14006692089606076], [0.9596591647714376], [0.16373594224262542]]
0.17237977705601798
Epoch 1/20, train_loss: 0.0651, avg_val_loss: 0.1724
[[0.17237977705601798, 0.15234155509676925], [0.28971270478952427, 0.2666529653528437], [0.15825580240200504, 0.13878781611498553], [0.14006692089606076, 0.1272078265901655], [0.9596591647714376, 0.8500485084950924], [0.16373594224262542, 0.1430928121073939]]
0.15234155509676925
Epoch 2/20, train_loss: 0.0913, avg_val_loss: 0.1523
[[0.17237977705601798, 0.15234155509676925, 0.15196481427436875], [0.28971270478952427, 0.2666529653528437, 0.25842565263564976], [0.15825580240200504, 0.13878781611498553, 0.13344482904353652], [0.14006692089606076, 0.1272078265901655, 0.12624491623137146], [0.9596591647714376, 0.8500485084950924, 0.9059955235570669], [0.16373594224262542, 0.1430928121073939, 0.14558373502315805]]
0.15196481427436875
Epoch 3/20, train_loss: 0.2299, avg_val_loss: 0.1520
[[0.17237977705601798, 0.15234155509676925, 0.15196481427436875, 0.14767969612389298], [0.28971270478952427, 0.2666529653528437, 0.25842565263564976, 0.2479889758478719], [0.15825580240200504, 0.13878781611498553, 0.13344482904353652, 0.1339070518893865], [0.14006692089606076, 0.1272078265901655, 0.12624491623137146, 0.1272559604840353], [0.9596591647714376, 0.8500485084950924, 0.9059955235570669, 0.947699761018157], [0.16373594224262542, 0.1430928121073939, 0.14558373502315805, 0.13762815478748788]]
0.14767969612389298
Epoch 4/20, train_loss: 0.1146, avg_val_loss: 0.1477
[[0.17237977705601798, 0.15234155509676925, 0.15196481427436875, 0.14767969612389298, 0.15146542733090518], [0.28971270478952427, 0.2666529653528437, 0.25842565263564976, 0.2479889758478719, 0.2493831566847361], [0.15825580240200504, 0.13878781611498553, 0.13344482904353652, 0.1339070518893865, 0.1377931808422025], [0.14006692089606076, 0.1272078265901655, 0.12624491623137146, 0.1272559604840353, 0.13792138220742345], [0.9596591647714376, 0.8500485084950924, 0.9059955235570669, 0.947699761018157, 0.9437585342675447], [0.16373594224262542, 0.1430928121073939, 0.14558373502315805, 0.13762815478748788, 0.14296129411949327]]
0.15146542733090518
Epoch 5/20, train_loss: 0.0317, avg_val_loss: 0.1515
[[0.17237977705601798, 0.15234155509676925, 0.15196481427436875, 0.14767969612389298, 0.15146542733090518, 0.15043182935236596], [0.28971270478952427, 0.2666529653528437, 0.25842565263564976, 0.2479889758478719, 0.2493831566847361, 0.25209104710112745], [0.15825580240200504, 0.13878781611498553, 0.13344482904353652, 0.1339070518893865, 0.1377931808422025, 0.1367420720579192], [0.14006692089606076, 0.1272078265901655, 0.12624491623137146, 0.1272559604840353, 0.13792138220742345, 0.13740649330429733], [0.9596591647714376, 0.8500485084950924, 0.9059955235570669, 0.947699761018157, 0.9437585342675447, 1.0880408249795437], [0.16373594224262542, 0.1430928121073939, 0.14558373502315805, 0.13762815478748788, 0.14296129411949327, 0.14227995235687152]]
0.15043182935236596
Epoch 6/20, train_loss: 0.0481, avg_val_loss: 0.1504
[[0.17237977705601798, 0.15234155509676925, 0.15196481427436875, 0.14767969612389298, 0.15146542733090518, 0.15043182935236596, 0.16771218590035727], [0.28971270478952427, 0.2666529653528437, 0.25842565263564976, 0.2479889758478719, 0.2493831566847361, 0.25209104710112745, 0.27909422442674064], [0.15825580240200504, 0.13878781611498553, 0.13344482904353652, 0.1339070518893865, 0.1377931808422025, 0.1367420720579192, 0.15168856028854227], [0.14006692089606076, 0.1272078265901655, 0.12624491623137146, 0.1272559604840353, 0.13792138220742345, 0.13740649330429733, 0.15107139269821346], [0.9596591647714376, 0.8500485084950924, 0.9059955235570669, 0.947699761018157, 0.9437585342675447, 1.0880408249795437, 1.1713601257652044], [0.16373594224262542, 0.1430928121073939, 0.14558373502315805, 0.13762815478748788, 0.14296129411949327, 0.14227995235687152, 0.15429720034549077]]
0.16771218590035727
Epoch 7/20, train_loss: 0.0713, avg_val_loss: 0.1677
Early stopping at epoch 7 as avg validation loss has not decreased for 3 epochs since epoch-3.
Test Set(en): ('Len: 10001', 'Tokens: 80535', 'Unique: 20221', "Entities: {'O': 40875, 'I-ORG': 11638, 'I-PER': 7520, 'I-LOC': 6357, 'B-LOC': 4834, 'B-ORG': 4676, 'B-PER': 4635}")
Test Set(it): ('Len: 10000', 'Tokens: 80005', 'Unique: 18461', "Entities: {'O': 47357, 'I-ORG': 8992, 'I-PER': 5863, 'B-PER': 4911, 'B-LOC': 4600, 'I-LOC': 4166, 'B-ORG': 4116}")
Test Set(af): ('Len: 1000', 'Tokens: 10894', 'Unique: 3404', "Entities: {'O': 7764, 'I-ORG': 911, 'B-ORG': 583, 'I-PER': 548, 'B-LOC': 529, 'B-PER': 370, 'I-LOC': 189}")
Test Set(sw): ('Len: 1000', 'Tokens: 5609', 'Unique: 1830', "Entities: {'O': 2412, 'I-ORG': 696, 'I-PER': 674, 'I-LOC': 618, 'B-LOC': 452, 'B-PER': 403, 'B-ORG': 354}")
Test Set(de): ('Len: 10000', 'Tokens: 97805', 'Unique: 23570', "Entities: {'O': 69057, 'I-PER': 6539, 'I-ORG': 6107, 'B-LOC': 4968, 'B-PER': 4569, 'B-ORG': 4281, 'I-LOC': 2284}")
LANG [en]: F1-score (Token-level) : 0.849
Test Loss: 0.27909422442674064 
 Test Evaluation (strict IOB2):
              precision    recall  f1-score   support

         LOC      0.887     0.879     0.883      9463
         ORG      0.800     0.755     0.777      7848
         PER      0.893     0.913     0.903      7491

   micro avg      0.863     0.850     0.857     24802
   macro avg      0.860     0.849     0.855     24802
weighted avg      0.862     0.850     0.856     24802

LANG [it]: F1-score (Token-level) : 0.919
Test Loss: 0.15168856028854227 
 Test Evaluation (strict IOB2):
              precision    recall  f1-score   support

         LOC      0.921     0.914     0.918      9427
         ORG      0.887     0.877     0.882      7224
         PER      0.963     0.965     0.964      8423

   micro avg      0.925     0.921     0.923     25074
   macro avg      0.923     0.919     0.921     25074
weighted avg      0.925     0.921     0.923     25074

LANG [af]: F1-score (Token-level) : 0.897
Test Loss: 0.15107139269821346 
 Test Evaluation (strict IOB2):
              precision    recall  f1-score   support

         LOC      0.868     0.903     0.885      1296
         ORG      0.868     0.915     0.891      1304
         PER      0.929     0.958     0.943       666

   micro avg      0.880     0.919     0.899      3266
   macro avg      0.888     0.925     0.906      3266
weighted avg      0.880     0.919     0.899      3266

LANG [sw]: F1-score (Token-level) : 0.671
Test Loss: 1.1713601257652044 
 Test Evaluation (strict IOB2):
              precision    recall  f1-score   support

         LOC      0.619     0.729     0.670       908
         ORG      0.579     0.454     0.509       701
         PER      0.869     0.848     0.858       617

   micro avg      0.677     0.675     0.676      2226
   macro avg      0.689     0.677     0.679      2226
weighted avg      0.676     0.675     0.671      2226

LANG [de]: F1-score (Token-level) : 0.883
Test Loss: 0.15429720034549077 
 Test Evaluation (strict IOB2):
              precision    recall  f1-score   support

         LOC      0.887     0.912     0.900     11290
         ORG      0.837     0.830     0.833      9151
         PER      0.940     0.914     0.927      7933

   micro avg      0.885     0.886     0.886     28374
   macro avg      0.888     0.886     0.887     28374
weighted avg      0.885     0.886     0.886     28374

Time Elapsed:  8465.834288358688
