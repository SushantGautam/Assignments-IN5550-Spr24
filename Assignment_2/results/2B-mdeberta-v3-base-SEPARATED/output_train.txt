Warning: 3 rows excluded due to sparse bins.
Train Language(s): ['en', 'de']
Train Set: ('Len: 31997', 'Tokens: 283849', 'Unique: 56229', "Entities: {'O': 174621, 'I-ORG': 28281, 'I-PER': 22501, 'B-LOC': 15070, 'B-PER': 14800, 'B-ORG': 14312, 'I-LOC': 14264}")
Val Set: ('Len: 8000', 'Tokens: 71181', 'Unique: 20755', "Entities: {'O': 43951, 'I-ORG': 7191, 'I-PER': 5527, 'B-LOC': 3824, 'B-ORG': 3685, 'B-PER': 3654, 'I-LOC': 3349}")
Test Set(en): ('Len: 10001', 'Tokens: 80535', 'Unique: 20221', "Entities: {'O': 40875, 'I-ORG': 11638, 'I-PER': 7520, 'I-LOC': 6357, 'B-LOC': 4834, 'B-ORG': 4676, 'B-PER': 4635}")
Test Set(it): ('Len: 10000', 'Tokens: 80005', 'Unique: 18461', "Entities: {'O': 47357, 'I-ORG': 8992, 'I-PER': 5863, 'B-PER': 4911, 'B-LOC': 4600, 'I-LOC': 4166, 'B-ORG': 4116}")
Test Set(af): ('Len: 1000', 'Tokens: 10894', 'Unique: 3404', "Entities: {'O': 7764, 'I-ORG': 911, 'B-ORG': 583, 'I-PER': 548, 'B-LOC': 529, 'B-PER': 370, 'I-LOC': 189}")
Test Set(sw): ('Len: 1000', 'Tokens: 5609', 'Unique: 1830', "Entities: {'O': 2412, 'I-ORG': 696, 'I-PER': 674, 'I-LOC': 618, 'B-LOC': 452, 'B-PER': 403, 'B-ORG': 354}")
Test Set(de): ('Len: 10000', 'Tokens: 97805', 'Unique: 23570', "Entities: {'O': 69057, 'I-PER': 6539, 'I-ORG': 6107, 'B-LOC': 4968, 'B-PER': 4569, 'B-ORG': 4281, 'I-LOC': 2284}")
Trainable parameters:  278,224,135
[[0.22222535835206508], [0.2997505055686917], [0.25001721457837106], [0.21481934073381126], [0.8874284699559212], [0.16743051799865197]]
0.22222535835206508
Epoch 1/20, train_loss: 0.2904, avg_val_loss: 0.2222
[[0.22222535835206508, 0.20370847567915917], [0.2997505055686917, 0.26956135739152803], [0.25001721457837106, 0.23302166682843584], [0.21481934073381126, 0.23397496168036014], [0.8874284699559212, 0.8905151449143887], [0.16743051799865197, 0.1572121074095892]]
0.20370847567915917
Epoch 2/20, train_loss: 0.2019, avg_val_loss: 0.2037
[[0.22222535835206508, 0.20370847567915917, 0.19406326067447663], [0.2997505055686917, 0.26956135739152803, 0.2580072862771563], [0.25001721457837106, 0.23302166682843584, 0.22706892721640606], [0.21481934073381126, 0.23397496168036014, 0.2081061250064522], [0.8874284699559212, 0.8905151449143887, 0.9407470673322678], [0.16743051799865197, 0.1572121074095892, 0.14414094675320405]]
0.19406326067447663
Epoch 3/20, train_loss: 0.0573, avg_val_loss: 0.1941
[[0.22222535835206508, 0.20370847567915917, 0.19406326067447663, 0.19689230358600615], [0.2997505055686917, 0.26956135739152803, 0.2580072862771563, 0.2594464039578796], [0.25001721457837106, 0.23302166682843584, 0.22706892721640606, 0.2315623070568608], [0.21481934073381126, 0.23397496168036014, 0.2081061250064522, 0.20302348537370563], [0.8874284699559212, 0.8905151449143887, 0.9407470673322678, 0.9950915202498436], [0.16743051799865197, 0.1572121074095892, 0.14414094675320405, 0.14549283800533594]]
0.19689230358600615
Epoch 4/20, train_loss: 0.1292, avg_val_loss: 0.1969
[[0.22222535835206508, 0.20370847567915917, 0.19406326067447663, 0.19689230358600615, 0.20786244598776102], [0.2997505055686917, 0.26956135739152803, 0.2580072862771563, 0.2594464039578796, 0.2679132049242719], [0.25001721457837106, 0.23302166682843584, 0.22706892721640606, 0.2315623070568608, 0.240647923885681], [0.21481934073381126, 0.23397496168036014, 0.2081061250064522, 0.20302348537370563, 0.24403746984899044], [0.8874284699559212, 0.8905151449143887, 0.9407470673322678, 0.9950915202498436, 1.0876836478710175], [0.16743051799865197, 0.1572121074095892, 0.14414094675320405, 0.14549283800533594, 0.15519360827502257]]
0.20786244598776102
Epoch 5/20, train_loss: 0.0886, avg_val_loss: 0.2079
[[0.22222535835206508, 0.20370847567915917, 0.19406326067447663, 0.19689230358600615, 0.20786244598776102, 0.20176654590666293], [0.2997505055686917, 0.26956135739152803, 0.2580072862771563, 0.2594464039578796, 0.2679132049242719, 0.26609608245352967], [0.25001721457837106, 0.23302166682843584, 0.22706892721640606, 0.2315623070568608, 0.240647923885681, 0.23667179199810418], [0.21481934073381126, 0.23397496168036014, 0.2081061250064522, 0.20302348537370563, 0.24403746984899044, 0.23839102848432958], [0.8874284699559212, 0.8905151449143887, 0.9407470673322678, 0.9950915202498436, 1.0876836478710175, 1.1062268912792206], [0.16743051799865197, 0.1572121074095892, 0.14414094675320405, 0.14549283800533594, 0.15519360827502257, 0.14790627462105058]]
0.20176654590666293
Epoch 6/20, train_loss: 0.0625, avg_val_loss: 0.2018
Early stopping at epoch 6 as avg validation loss has not decreased for 3 epochs since epoch-2.
Test Set(en): ('Len: 10001', 'Tokens: 80535', 'Unique: 20221', "Entities: {'O': 40875, 'I-ORG': 11638, 'I-PER': 7520, 'I-LOC': 6357, 'B-LOC': 4834, 'B-ORG': 4676, 'B-PER': 4635}")
Test Set(it): ('Len: 10000', 'Tokens: 80005', 'Unique: 18461', "Entities: {'O': 47357, 'I-ORG': 8992, 'I-PER': 5863, 'B-PER': 4911, 'B-LOC': 4600, 'I-LOC': 4166, 'B-ORG': 4116}")
Test Set(af): ('Len: 1000', 'Tokens: 10894', 'Unique: 3404', "Entities: {'O': 7764, 'I-ORG': 911, 'B-ORG': 583, 'I-PER': 548, 'B-LOC': 529, 'B-PER': 370, 'I-LOC': 189}")
Test Set(sw): ('Len: 1000', 'Tokens: 5609', 'Unique: 1830', "Entities: {'O': 2412, 'I-ORG': 696, 'I-PER': 674, 'I-LOC': 618, 'B-LOC': 452, 'B-PER': 403, 'B-ORG': 354}")
Test Set(de): ('Len: 10000', 'Tokens: 97805', 'Unique: 23570', "Entities: {'O': 69057, 'I-PER': 6539, 'I-ORG': 6107, 'B-LOC': 4968, 'B-PER': 4569, 'B-ORG': 4281, 'I-LOC': 2284}")
LANG [en]: F1-score (Token-level) : 0.845
Test Loss: 0.26609608245352967 
 Test Evaluation (strict IOB2):
              precision    recall  f1-score   support

         LOC      0.848     0.912     0.879      9463
         ORG      0.817     0.725     0.768      7848
         PER      0.896     0.914     0.905      7491

   micro avg      0.854     0.854     0.854     24802
   macro avg      0.854     0.850     0.851     24802
weighted avg      0.853     0.854     0.852     24802

LANG [it]: F1-score (Token-level) : 0.860
Test Loss: 0.23667179199810418 
 Test Evaluation (strict IOB2):
              precision    recall  f1-score   support

         LOC      0.843     0.844     0.844      9427
         ORG      0.819     0.790     0.804      7224
         PER      0.946     0.949     0.947      8423

   micro avg      0.871     0.864     0.867     25074
   macro avg      0.869     0.861     0.865     25074
weighted avg      0.871     0.864     0.867     25074

LANG [af]: F1-score (Token-level) : 0.827
Test Loss: 0.23839102848432958 
 Test Evaluation (strict IOB2):
              precision    recall  f1-score   support

         LOC      0.755     0.911     0.826      1296
         ORG      0.835     0.790     0.812      1304
         PER      0.836     0.929     0.881       666

   micro avg      0.800     0.867     0.832      3266
   macro avg      0.809     0.877     0.839      3266
weighted avg      0.803     0.867     0.831      3266

LANG [sw]: F1-score (Token-level) : 0.659
Test Loss: 1.1062268912792206 
 Test Evaluation (strict IOB2):
              precision    recall  f1-score   support

         LOC      0.587     0.742     0.656       908
         ORG      0.650     0.392     0.489       701
         PER      0.857     0.844     0.851       617

   micro avg      0.675     0.660     0.667      2226
   macro avg      0.698     0.660     0.665      2226
weighted avg      0.682     0.660     0.657      2226

LANG [de]: F1-score (Token-level) : 0.872
Test Loss: 0.14790627462105058 
 Test Evaluation (strict IOB2):
              precision    recall  f1-score   support

         LOC      0.860     0.920     0.889     11290
         ORG      0.832     0.805     0.818      9151
         PER      0.931     0.912     0.921      7933

   micro avg      0.871     0.881     0.876     28374
   macro avg      0.874     0.879     0.876     28374
weighted avg      0.871     0.881     0.875     28374

Time Elapsed:  4031.537029981613
