Warning: 2 rows excluded due to sparse bins.
Train Language(s): ['en', 'it', 'de']
Train Set: ('Len: 47999', 'Tokens: 414049', 'Unique: 75207', "Entities: {'O': 252393, 'I-ORG': 42482, 'I-PER': 31666, 'B-LOC': 22935, 'B-PER': 22535, 'I-LOC': 21141, 'B-ORG': 20897}")
Val Set: ('Len: 12000', 'Tokens: 103552', 'Unique: 28380', "Entities: {'O': 63030, 'I-ORG': 10513, 'I-PER': 8094, 'B-LOC': 5812, 'B-PER': 5685, 'I-LOC': 5273, 'B-ORG': 5145}")
Test Set(en): ('Len: 10001', 'Tokens: 80535', 'Unique: 20221', "Entities: {'O': 40875, 'I-ORG': 11638, 'I-PER': 7520, 'I-LOC': 6357, 'B-LOC': 4834, 'B-ORG': 4676, 'B-PER': 4635}")
Test Set(it): ('Len: 10000', 'Tokens: 80005', 'Unique: 18461', "Entities: {'O': 47357, 'I-ORG': 8992, 'I-PER': 5863, 'B-PER': 4911, 'B-LOC': 4600, 'I-LOC': 4166, 'B-ORG': 4116}")
Test Set(af): ('Len: 1000', 'Tokens: 10894', 'Unique: 3404', "Entities: {'O': 7764, 'I-ORG': 911, 'B-ORG': 583, 'I-PER': 548, 'B-LOC': 529, 'B-PER': 370, 'I-LOC': 189}")
Test Set(sw): ('Len: 1000', 'Tokens: 5609', 'Unique: 1830', "Entities: {'O': 2412, 'I-ORG': 696, 'I-PER': 674, 'I-LOC': 618, 'B-LOC': 452, 'B-PER': 403, 'B-ORG': 354}")
Test Set(de): ('Len: 10000', 'Tokens: 97805', 'Unique: 23570', "Entities: {'O': 69057, 'I-PER': 6539, 'I-ORG': 6107, 'B-LOC': 4968, 'B-PER': 4569, 'B-ORG': 4281, 'I-LOC': 2284}")
Trainable parameters:  278,224,135
[[0.19546843052903812], [0.2928325356052706], [0.16720387477653856], [0.22062606480903924], [0.9091409202665091], [0.16772000140513474]]
0.19546843052903812
Epoch 1/20, train_loss: 0.1305, avg_val_loss: 0.1955
[[0.19546843052903812, 0.17324422159790992], [0.2928325356052706, 0.26317111470590765], [0.16720387477653856, 0.14588170909819703], [0.22062606480903924, 0.20873128599487245], [0.9091409202665091, 0.9102287609130144], [0.16772000140513474, 0.15249925438826456]]
0.17324422159790992
Epoch 2/20, train_loss: 0.2927, avg_val_loss: 0.1732
[[0.19546843052903812, 0.17324422159790992, 0.1639734585682551], [0.2928325356052706, 0.26317111470590765, 0.2544846631967412], [0.16720387477653856, 0.14588170909819703, 0.13801984133692785], [0.22062606480903924, 0.20873128599487245, 0.2119844276458025], [0.9091409202665091, 0.9102287609130144, 0.9710563011467457], [0.16772000140513474, 0.15249925438826456, 0.14449715763687515]]
0.1639734585682551
Epoch 3/20, train_loss: 0.1330, avg_val_loss: 0.1640
[[0.19546843052903812, 0.17324422159790992, 0.1639734585682551, 0.16411657452831666], [0.2928325356052706, 0.26317111470590765, 0.2544846631967412, 0.2531790055405979], [0.16720387477653856, 0.14588170909819703, 0.13801984133692785, 0.1416025815067438], [0.22062606480903924, 0.20873128599487245, 0.2119844276458025, 0.23983374563977122], [0.9091409202665091, 0.9102287609130144, 0.9710563011467457, 1.0067542362958193], [0.16772000140513474, 0.15249925438826456, 0.14449715763687515, 0.14331295445989878]]
0.16411657452831666
Epoch 4/20, train_loss: 0.1611, avg_val_loss: 0.1641
[[0.19546843052903812, 0.17324422159790992, 0.1639734585682551, 0.16411657452831666, 0.16730798994749785], [0.2928325356052706, 0.26317111470590765, 0.2544846631967412, 0.2531790055405979, 0.25998846852122404], [0.16720387477653856, 0.14588170909819703, 0.13801984133692785, 0.1416025815067438, 0.14564080978966892], [0.22062606480903924, 0.20873128599487245, 0.2119844276458025, 0.23983374563977122, 0.23441223287954926], [0.9091409202665091, 0.9102287609130144, 0.9710563011467457, 1.0067542362958193, 1.0269297398626804], [0.16772000140513474, 0.15249925438826456, 0.14449715763687515, 0.14331295445989878, 0.14925744081029116]]
0.16730798994749785
Epoch 5/20, train_loss: 0.1247, avg_val_loss: 0.1673
[[0.19546843052903812, 0.17324422159790992, 0.1639734585682551, 0.16411657452831666, 0.16730798994749785, 0.17386320654551188], [0.2928325356052706, 0.26317111470590765, 0.2544846631967412, 0.2531790055405979, 0.25998846852122404, 0.264465293528649], [0.16720387477653856, 0.14588170909819703, 0.13801984133692785, 0.1416025815067438, 0.14564080978966892, 0.14862888510942981], [0.22062606480903924, 0.20873128599487245, 0.2119844276458025, 0.23983374563977122, 0.23441223287954926, 0.2666718037799001], [0.9091409202665091, 0.9102287609130144, 0.9710563011467457, 1.0067542362958193, 1.0269297398626804, 1.1101148910820484], [0.16772000140513474, 0.15249925438826456, 0.14449715763687515, 0.14331295445989878, 0.14925744081029116, 0.15407412211461285]]
0.17386320654551188
Epoch 6/20, train_loss: 0.1379, avg_val_loss: 0.1739
Early stopping at epoch 6 as avg validation loss has not decreased for 3 epochs since epoch-2.
Test Set(en): ('Len: 10001', 'Tokens: 80535', 'Unique: 20221', "Entities: {'O': 40875, 'I-ORG': 11638, 'I-PER': 7520, 'I-LOC': 6357, 'B-LOC': 4834, 'B-ORG': 4676, 'B-PER': 4635}")
Test Set(it): ('Len: 10000', 'Tokens: 80005', 'Unique: 18461', "Entities: {'O': 47357, 'I-ORG': 8992, 'I-PER': 5863, 'B-PER': 4911, 'B-LOC': 4600, 'I-LOC': 4166, 'B-ORG': 4116}")
Test Set(af): ('Len: 1000', 'Tokens: 10894', 'Unique: 3404', "Entities: {'O': 7764, 'I-ORG': 911, 'B-ORG': 583, 'I-PER': 548, 'B-LOC': 529, 'B-PER': 370, 'I-LOC': 189}")
Test Set(sw): ('Len: 1000', 'Tokens: 5609', 'Unique: 1830', "Entities: {'O': 2412, 'I-ORG': 696, 'I-PER': 674, 'I-LOC': 618, 'B-LOC': 452, 'B-PER': 403, 'B-ORG': 354}")
Test Set(de): ('Len: 10000', 'Tokens: 97805', 'Unique: 23570', "Entities: {'O': 69057, 'I-PER': 6539, 'I-ORG': 6107, 'B-LOC': 4968, 'B-PER': 4569, 'B-ORG': 4281, 'I-LOC': 2284}")
LANG [en]: F1-score (Token-level) : 0.848
Test Loss: 0.264465293528649 
 Test Evaluation (strict IOB2):
              precision    recall  f1-score   support

         LOC      0.870     0.886     0.878      9463
         ORG      0.782     0.780     0.781      7848
         PER      0.914     0.898     0.906      7491

   micro avg      0.855     0.856     0.855     24802
   macro avg      0.855     0.854     0.855     24802
weighted avg      0.855     0.856     0.855     24802

LANG [it]: F1-score (Token-level) : 0.915
Test Loss: 0.14862888510942981 
 Test Evaluation (strict IOB2):
              precision    recall  f1-score   support

         LOC      0.909     0.914     0.912      9427
         ORG      0.873     0.880     0.877      7224
         PER      0.975     0.957     0.966      8423

   micro avg      0.920     0.919     0.919     25074
   macro avg      0.919     0.917     0.918     25074
weighted avg      0.921     0.919     0.920     25074

LANG [af]: F1-score (Token-level) : 0.831
Test Loss: 0.2666718037799001 
 Test Evaluation (strict IOB2):
              precision    recall  f1-score   support

         LOC      0.790     0.890     0.837      1296
         ORG      0.785     0.832     0.808      1304
         PER      0.856     0.911     0.883       666

   micro avg      0.801     0.871     0.835      3266
   macro avg      0.810     0.878     0.842      3266
weighted avg      0.801     0.871     0.835      3266

LANG [sw]: F1-score (Token-level) : 0.675
Test Loss: 1.1101148910820484 
 Test Evaluation (strict IOB2):
              precision    recall  f1-score   support

         LOC      0.634     0.731     0.679       908
         ORG      0.571     0.488     0.526       701
         PER      0.907     0.810     0.856       617

   micro avg      0.685     0.677     0.681      2226
   macro avg      0.704     0.677     0.687      2226
weighted avg      0.690     0.677     0.680      2226

LANG [de]: F1-score (Token-level) : 0.871
Test Loss: 0.15407412211461285 
 Test Evaluation (strict IOB2):
              precision    recall  f1-score   support

         LOC      0.886     0.903     0.894     11290
         ORG      0.780     0.838     0.808      9151
         PER      0.956     0.897     0.925      7933

   micro avg      0.868     0.880     0.874     28374
   macro avg      0.874     0.879     0.876     28374
weighted avg      0.871     0.880     0.875     28374

Time Elapsed:  5500.929141283035
